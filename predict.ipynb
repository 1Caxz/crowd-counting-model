{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14eb4f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34-peoples.jpg: Estimated Count = 54.78\n",
      "271-peoples.jpg: Estimated Count = 175.04\n",
      "93-peoples.jpg: Estimated Count = 103.10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import resize as tvf_resize\n",
    "from models.csrnet_mbv3 import MobileCSRNet\n",
    "\n",
    "# ==== Config ====\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_DIR = \"inference/test_images\"\n",
    "# MODEL_PATH = \"build/csrnet_vgg_B.pth\"\n",
    "MODEL_PATH = \"build/csrnet_mobile_B.pt\"\n",
    "SAVE_HEATMAP = True  # Set False jika tidak ingin simpan visualisasi density map\n",
    "HEATMAP_DIR = \"inference/heatmaps\"\n",
    "\n",
    "os.makedirs(HEATMAP_DIR, exist_ok=True)\n",
    "\n",
    "# ==== Transform ====\n",
    "# transform = transforms.Compose([\n",
    "#     # transforms.Resize((384, 384)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                          std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "# ])\n",
    "\n",
    "m_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                            [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ==== Load Model ====\n",
    "model = MobileCSRNet().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE, weights_only=False))\n",
    "# checkpoint = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=False)\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# print(f\"MAE: {checkpoint['best_prec1']} - epoch: {checkpoint['epoch']}\")\n",
    "model.eval()\n",
    "\n",
    "# ==== Predict ====\n",
    "image_files = [f for f in os.listdir(\n",
    "    IMAGE_DIR) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "for fname in image_files:\n",
    "    path = os.path.join(IMAGE_DIR, fname)\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    input_img = m_transform(image).unsqueeze(0).to(DEVICE)  # [1, 3, 384, 384]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_img)  # [1, 1, H, W]\n",
    "        density_map = output.squeeze().cpu().numpy()\n",
    "        total_count = density_map.sum()\n",
    "\n",
    "    print(f\"{fname}: Estimated Count = {total_count:.2f}\")\n",
    "\n",
    "    # Optional: Save heatmap\n",
    "    if SAVE_HEATMAP:\n",
    "        # plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(density_map, cmap='jet')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Count: {total_count:.1f}')\n",
    "        heatmap_path = os.path.join(\n",
    "            HEATMAP_DIR, fname.replace('.jpg', '_heatmap.png'))\n",
    "        plt.savefig(heatmap_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
