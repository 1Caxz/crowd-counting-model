{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d884bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   2%|▏         | 4/182 [00:00<00:05, 29.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 172.00\t Predict 259.14\n",
      "GT 502.00\t Predict 377.42\n",
      "GT 389.00\t Predict 366.59\n",
      "GT 211.00\t Predict 208.89\n",
      "GT 223.00\t Predict 244.75\n",
      "GT 430.00\t Predict 450.88\n",
      "GT 1174.00\t Predict 1304.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   6%|▌         | 11/182 [00:00<00:06, 25.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 265.00\t Predict 210.70\n",
      "GT 1232.00\t Predict 1178.56\n",
      "GT 289.00\t Predict 195.10\n",
      "GT 181.00\t Predict 179.15\n",
      "GT 379.00\t Predict 367.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   9%|▉         | 17/182 [00:00<00:06, 25.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 1068.00\t Predict 979.64\n",
      "GT 1020.00\t Predict 648.86\n",
      "GT 452.00\t Predict 573.78\n",
      "GT 256.00\t Predict 321.37\n",
      "GT 66.00\t Predict 166.89\n",
      "GT 141.00\t Predict 162.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▎        | 25/182 [00:00<00:05, 28.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 1191.00\t Predict 1162.42\n",
      "GT 288.00\t Predict 323.20\n",
      "GT 1603.00\t Predict 1490.75\n",
      "GT 241.00\t Predict 316.01\n",
      "GT 250.00\t Predict 264.30\n",
      "GT 321.00\t Predict 164.84\n",
      "GT 133.00\t Predict 191.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  16%|█▌        | 29/182 [00:01<00:05, 28.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 1210.00\t Predict 1139.87\n",
      "GT 1152.00\t Predict 574.36\n",
      "GT 115.00\t Predict 116.26\n",
      "GT 226.00\t Predict 190.51\n",
      "GT 269.00\t Predict 333.36\n",
      "GT 440.00\t Predict 304.71\n",
      "GT 983.00\t Predict 562.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  20%|█▉        | 36/182 [00:01<00:05, 25.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 419.00\t Predict 364.32\n",
      "GT 298.00\t Predict 253.57\n",
      "GT 584.00\t Predict 533.62\n",
      "GT 921.00\t Predict 779.35\n",
      "GT 603.00\t Predict 487.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  24%|██▍       | 44/182 [00:01<00:04, 27.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 375.00\t Predict 324.66\n",
      "GT 135.00\t Predict 124.70\n",
      "GT 165.00\t Predict 147.11\n",
      "GT 72.00\t Predict 48.35\n",
      "GT 102.00\t Predict 72.48\n",
      "GT 488.00\t Predict 476.33\n",
      "GT 292.00\t Predict 286.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  26%|██▌       | 47/182 [00:01<00:05, 25.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 355.00\t Predict 308.06\n",
      "GT 762.00\t Predict 592.31\n",
      "GT 93.00\t Predict 91.11\n",
      "GT 475.00\t Predict 393.69\n",
      "GT 211.00\t Predict 202.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▉       | 53/182 [00:01<00:05, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 356.00\t Predict 309.84\n",
      "GT 262.00\t Predict 220.08\n",
      "GT 261.00\t Predict 173.59\n",
      "GT 479.00\t Predict 526.93\n",
      "GT 587.00\t Predict 537.23\n",
      "GT 208.00\t Predict 166.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  32%|███▏      | 59/182 [00:02<00:04, 24.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 230.00\t Predict 184.89\n",
      "GT 341.00\t Predict 316.73\n",
      "GT 1303.00\t Predict 1066.09\n",
      "GT 253.00\t Predict 195.60\n",
      "GT 277.00\t Predict 263.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  36%|███▌      | 65/182 [00:02<00:04, 23.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 395.00\t Predict 378.23\n",
      "GT 495.00\t Predict 502.41\n",
      "GT 165.00\t Predict 239.76\n",
      "GT 199.00\t Predict 138.30\n",
      "GT 390.00\t Predict 397.42\n",
      "GT 308.00\t Predict 438.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  39%|███▉      | 71/182 [00:02<00:04, 24.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 199.00\t Predict 248.55\n",
      "GT 416.00\t Predict 427.64\n",
      "GT 121.00\t Predict 147.66\n",
      "GT 266.00\t Predict 278.40\n",
      "GT 219.00\t Predict 256.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  41%|████      | 74/182 [00:02<00:04, 22.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 162.00\t Predict 300.53\n",
      "GT 302.00\t Predict 275.82\n",
      "GT 1581.00\t Predict 741.44\n",
      "GT 126.00\t Predict 177.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  44%|████▍     | 80/182 [00:03<00:04, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 112.00\t Predict 107.47\n",
      "GT 240.00\t Predict 322.53\n",
      "GT 218.00\t Predict 315.51\n",
      "GT 1156.00\t Predict 1086.66\n",
      "GT 669.00\t Predict 584.27\n",
      "GT 238.00\t Predict 234.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  47%|████▋     | 86/182 [00:03<00:03, 24.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 1171.00\t Predict 735.98\n",
      "GT 480.00\t Predict 695.59\n",
      "GT 129.00\t Predict 177.35\n",
      "GT 442.00\t Predict 533.65\n",
      "GT 213.00\t Predict 298.71\n",
      "GT 363.00\t Predict 417.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  51%|█████     | 93/182 [00:03<00:03, 26.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 548.00\t Predict 498.37\n",
      "GT 400.00\t Predict 277.20\n",
      "GT 227.00\t Predict 128.00\n",
      "GT 398.00\t Predict 262.39\n",
      "GT 216.00\t Predict 205.94\n",
      "GT 199.00\t Predict 197.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  54%|█████▍    | 99/182 [00:03<00:03, 26.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 230.00\t Predict 184.52\n",
      "GT 1111.00\t Predict 1044.76\n",
      "GT 460.00\t Predict 655.37\n",
      "GT 716.00\t Predict 579.88\n",
      "GT 212.00\t Predict 253.87\n",
      "GT 429.00\t Predict 315.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  57%|█████▋    | 103/182 [00:04<00:02, 27.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 553.00\t Predict 547.06\n",
      "GT 243.00\t Predict 163.93\n",
      "GT 497.00\t Predict 267.61\n",
      "GT 760.00\t Predict 931.95\n",
      "GT 423.00\t Predict 493.67\n",
      "GT 309.00\t Predict 150.12\n",
      "GT 297.00\t Predict 394.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  59%|█████▉    | 107/182 [00:04<00:02, 29.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 307.00\t Predict 309.28\n",
      "GT 250.00\t Predict 250.56\n",
      "GT 959.00\t Predict 895.86\n",
      "GT 474.00\t Predict 299.90\n",
      "GT 89.00\t Predict 71.71\n",
      "GT 567.00\t Predict 390.93\n",
      "GT 1265.00\t Predict 665.46\n",
      "GT 195.00\t Predict 192.66\n",
      "GT 717.00\t Predict 638.21\n",
      "GT 196.00\t Predict 147.27\n",
      "GT 170.00\t Predict 172.57\n",
      "GT 236.00\t Predict 214.65\n",
      "GT 249.00\t Predict 192.50\n",
      "GT 797.00\t Predict 714.95\n",
      "GT 116.00\t Predict 107.72\n",
      "GT 365.00\t Predict 322.23\n",
      "GT 138.00\t Predict 174.35\n",
      "GT 373.00\t Predict 433.69\n",
      "GT 316.00\t Predict 451.35\n",
      "GT 384.00\t Predict 409.26\n",
      "GT 511.00\t Predict 505.47\n",
      "GT 817.00\t Predict 656.63\n",
      "GT 997.00\t Predict 955.25\n",
      "GT 297.00\t Predict 311.20\n",
      "GT 134.00\t Predict 109.29\n",
      "GT 175.00\t Predict 181.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  75%|███████▍  | 136/182 [00:04<00:00, 94.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 529.00\t Predict 683.86\n",
      "GT 149.00\t Predict 137.68\n",
      "GT 349.00\t Predict 297.36\n",
      "GT 356.00\t Predict 398.04\n",
      "GT 198.00\t Predict 185.44\n",
      "GT 466.00\t Predict 482.84\n",
      "GT 361.00\t Predict 440.66\n",
      "GT 291.00\t Predict 363.30\n",
      "GT 193.00\t Predict 154.60\n",
      "GT 337.00\t Predict 305.40\n",
      "GT 1114.00\t Predict 637.72\n",
      "GT 287.00\t Predict 339.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  80%|████████  | 146/182 [00:04<00:00, 56.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 214.00\t Predict 257.49\n",
      "GT 823.00\t Predict 763.48\n",
      "GT 192.00\t Predict 256.02\n",
      "GT 212.00\t Predict 193.64\n",
      "GT 166.00\t Predict 136.91\n",
      "GT 567.00\t Predict 465.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  85%|████████▍ | 154/182 [00:04<00:00, 45.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 412.00\t Predict 419.20\n",
      "GT 602.00\t Predict 620.94\n",
      "GT 589.00\t Predict 702.52\n",
      "GT 153.00\t Predict 159.81\n",
      "GT 855.00\t Predict 973.71\n",
      "GT 665.00\t Predict 525.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  88%|████████▊ | 161/182 [00:05<00:00, 38.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 482.00\t Predict 547.60\n",
      "GT 207.00\t Predict 216.30\n",
      "GT 271.00\t Predict 272.07\n",
      "GT 186.00\t Predict 166.36\n",
      "GT 1324.00\t Predict 546.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  92%|█████████▏| 167/182 [00:05<00:00, 35.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 157.00\t Predict 159.46\n",
      "GT 356.00\t Predict 360.15\n",
      "GT 217.00\t Predict 206.08\n",
      "GT 218.00\t Predict 242.81\n",
      "GT 122.00\t Predict 173.27\n",
      "GT 97.00\t Predict 86.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  95%|█████████▍| 172/182 [00:05<00:00, 33.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 579.00\t Predict 537.93\n",
      "GT 417.00\t Predict 392.92\n",
      "GT 86.00\t Predict 83.82\n",
      "GT 382.00\t Predict 425.22\n",
      "GT 371.00\t Predict 273.23\n",
      "GT 2256.00\t Predict 1408.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  99%|█████████▉| 180/182 [00:05<00:00, 32.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 101.00\t Predict 101.22\n",
      "GT 1365.00\t Predict 1281.41\n",
      "GT 255.00\t Predict 220.43\n",
      "GT 69.00\t Predict 56.85\n",
      "GT 190.00\t Predict 141.85\n",
      "GT 246.00\t Predict 214.27\n",
      "GT 477.00\t Predict 581.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 182/182 [00:05<00:00, 30.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 153.00\t Predict 160.43\n",
      "GT 242.00\t Predict 148.56\n",
      "\n",
      "Evaluation Results:\n",
      "  MAE  = 84.76\n",
      "  RMSE = 157.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from models.csrnet_tinyvgg import TinyCSRNet\n",
    "from models.csrnet_mbv3 import MobileCSRNet\n",
    "from models.csrnet_vgg import CSRNet\n",
    "\n",
    "# build/csrnet_vgg_B.pth\n",
    "# Evaluation Results:\n",
    "#   MAE  = 20.31\n",
    "#   RMSE = 37.47\n",
    "\n",
    "# build/best_kd_B_mobilenet_final.pth\n",
    "# Evaluation Results:\n",
    "#   MAE  = 23.37\n",
    "#   RMSE = 37.00\n",
    "\n",
    "MODEL=\"build/csrnet_vgg_A.pth\"\n",
    "PREDDIR=\"\"\n",
    "PART=\"A\"\n",
    "\n",
    "def load_model(model_path, device):\n",
    "    model = CSRNet().to(device)\n",
    "    # model.load_state_dict(torch.load(MODEL, map_location=device, weights_only=False))\n",
    "    checkpoint = torch.load(MODEL, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        # transforms.Resize((512, 512)),\n",
    "        # transforms.RandomHorizontalFlip(p=0.5),\n",
    "        # transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def predict_density(model, image_path, device):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = get_transform()(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor).cpu().squeeze(0).squeeze(0).numpy()\n",
    "    return output\n",
    "\n",
    "def evaluate(gt_dir, img_dir=None, model=None, pred_dir=None, device='cpu'):\n",
    "    mae, mse, total = 0.0, 0.0, 0\n",
    "    gt_files = sorted([f for f in os.listdir(gt_dir) if f.endswith('.h5')])\n",
    "\n",
    "    for fname in tqdm(gt_files, desc=\"Evaluating\"):\n",
    "        gt_path = os.path.join(gt_dir, fname)\n",
    "        with h5py.File(gt_path, 'r') as f:\n",
    "            gt_density = np.asarray(f['density'])\n",
    "        gt_count = gt_density.sum()\n",
    "\n",
    "        if model and img_dir:\n",
    "            img_path = os.path.join(img_dir, fname.replace('.h5', '.jpg').replace('GT_', ''))\n",
    "            pred_density = predict_density(model, img_path, device)\n",
    "        elif pred_dir:\n",
    "            pred_path = os.path.join(pred_dir, fname)\n",
    "            if not os.path.exists(pred_path):\n",
    "                print(f\"Missing prediction for {fname}, skipping.\")\n",
    "                continue\n",
    "            with h5py.File(pred_path, 'r') as f:\n",
    "                pred_density = np.asarray(f['density'])\n",
    "        else:\n",
    "            raise ValueError(\"Either model+img_dir or pred_dir must be provided.\")\n",
    "\n",
    "        pred_count = pred_density.sum()\n",
    "        # print(f\"GT {gt_count:.2f}\\t Predict {pred_count:.2f}\")\n",
    "        \n",
    "        error = abs(gt_count - pred_count)\n",
    "        mae += error\n",
    "        mse += error ** 2\n",
    "        total += 1\n",
    "\n",
    "    mae /= total\n",
    "    rmse = (mse / total) ** 0.5\n",
    "\n",
    "    print(f\"\\nEvaluation Results:\")\n",
    "    print(f\"  MAE  = {mae:.2f}\")\n",
    "    print(f\"  RMSE = {rmse:.2f}\")\n",
    "\n",
    "def main():\n",
    "    part = PART.upper()\n",
    "    root = os.path.abspath(\"dataset\")\n",
    "    gt_dir = os.path.join(root, f\"part_{part}\", \"test_data\", \"ground-truth\")\n",
    "    img_dir = os.path.join(root, f\"part_{part}\", \"test_data\", \"images\")\n",
    "\n",
    "    if not os.path.isdir(gt_dir):\n",
    "        raise FileNotFoundError(f\"Ground truth directory not found: {gt_dir}\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if MODEL:\n",
    "        model = load_model(MODEL, device)\n",
    "        evaluate(gt_dir, img_dir=img_dir, model=model, device=device)\n",
    "    elif PREDDIR:\n",
    "        pred_dir = os.path.abspath(PREDDIR)\n",
    "        evaluate(gt_dir, pred_dir=pred_dir)\n",
    "    else:\n",
    "        raise ValueError(\"You must provide either --model or --pred_dir\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b49c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::hardswish_ encountered 20 time(s)\n",
      "Unsupported operator aten::add_ encountered 10 time(s)\n",
      "Unsupported operator aten::hardsigmoid encountered 8 time(s)\n",
      "Unsupported operator aten::mul encountered 8 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPs: 3.90 GFLOPs\n",
      "Params: 13.66 M\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.csrnet_mbv3 import MobileCSRNet\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "\n",
    "MODEL=\"build/csrnet_mobile_A.pt\"\n",
    "\n",
    "# Inisialisasi model\n",
    "model = MobileCSRNet()\n",
    "model.load_state_dict(torch.load(MODEL, map_location='cpu', weights_only=False))\n",
    "# checkpoint = torch.load(MODEL, map_location=device, weights_only=False)\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Input dummy sesuai resolusi saat training\n",
    "dummy_input = torch.randn(1, 3, 512, 512)\n",
    "\n",
    "# Hitung FLOPs dan jumlah parameter\n",
    "flops = FlopCountAnalysis(model, dummy_input)\n",
    "params = parameter_count(model)\n",
    "\n",
    "print(f\"FLOPs: {flops.total() / 1e9:.2f} GFLOPs\")\n",
    "print(f\"Params: {params[''] / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b9f6330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 182/182 [00:03<00:00, 54.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "  MAE  = 169.73\n",
      "  RMSE = 278.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import transforms\n",
    "from models.csrnet_tinyvgg import TinyCSRNet\n",
    "from models.csrnet_mbv3 import MobileCSRNet\n",
    "from models.csrnet_vgg import CSRNet\n",
    "\n",
    "# build/csrnet_vgg_B.pth\n",
    "# Evaluation Results:\n",
    "#   MAE  = 20.31\n",
    "#   RMSE = 37.47\n",
    "\n",
    "# build/best_kd_B_mobilenet_final.pth\n",
    "# Evaluation Results:\n",
    "#   MAE  = 23.37\n",
    "#   RMSE = 37.00\n",
    "\n",
    "MODEL=\"build/csrnet_vgg_B.pth\"\n",
    "PREDDIR=\"\"\n",
    "PART=\"A\"\n",
    "\n",
    "def load_model(model_path, device):\n",
    "    model = CSRNet().to(device)\n",
    "    # model.load_state_dict(torch.load(MODEL, map_location=device, weights_only=False))\n",
    "    checkpoint = torch.load(MODEL, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        # transforms.Resize((512, 512)),\n",
    "        # transforms.RandomHorizontalFlip(p=0.5),\n",
    "        # transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def predict_density(model, image_path, device):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    # image = 255.0 * F.to_tensor(image)\n",
    "    # image[0,:,:]=image[0,:,:]-92.8207477031\n",
    "    # image[1,:,:]=image[1,:,:]-95.2757037428\n",
    "    # image[2,:,:]=image[2,:,:]-104.877445883\n",
    "    # input_tensor = image.cuda()\n",
    "    # input_tensor = get_transform()(image).unsqueeze(0).to(device)\n",
    "    input_tensor = get_transform()(image).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor.unsqueeze(0))\n",
    "    return output\n",
    "\n",
    "def evaluate(gt_dir, img_dir=None, model=None, pred_dir=None, device='cpu'):\n",
    "    mae, mse, total = 0.0, 0.0, 0\n",
    "    gt_files = sorted([f for f in os.listdir(gt_dir) if f.endswith('.h5')])\n",
    "\n",
    "    for fname in tqdm(gt_files, desc=\"Evaluating\"):\n",
    "        gt_path = os.path.join(gt_dir, fname)\n",
    "        with h5py.File(gt_path, 'r') as f:\n",
    "            gt_density = np.asarray(f['density'])\n",
    "        # gt_count = gt_density.sum()\n",
    "        gt_count = np.sum(gt_density)\n",
    "\n",
    "        if model and img_dir:\n",
    "            img_path = os.path.join(img_dir, fname.replace('.h5', '.jpg').replace('GT_', ''))\n",
    "            pred_density = predict_density(model, img_path, device)\n",
    "        elif pred_dir:\n",
    "            pred_path = os.path.join(pred_dir, fname)\n",
    "            if not os.path.exists(pred_path):\n",
    "                print(f\"Missing prediction for {fname}, skipping.\")\n",
    "                continue\n",
    "            with h5py.File(pred_path, 'r') as f:\n",
    "                pred_density = np.asarray(f['density'])\n",
    "        else:\n",
    "            raise ValueError(\"Either model+img_dir or pred_dir must be provided.\")\n",
    "\n",
    "        pred_count = pred_density.detach().cpu().sum().numpy()\n",
    "        # print(f\"GT {gt_count:.2f}\\t Predict {pred_count:.2f}\")\n",
    "        \n",
    "        error = abs(pred_count - gt_count)\n",
    "        mae += error\n",
    "        mse += error ** 2\n",
    "        total += 1\n",
    "\n",
    "    mae /= total\n",
    "    rmse = (mse / total) ** 0.5\n",
    "    # rmse = (mse / total)\n",
    "\n",
    "    print(f\"\\nEvaluation Results:\")\n",
    "    print(f\"  MAE  = {mae:.2f}\")\n",
    "    print(f\"  RMSE = {rmse:.2f}\")\n",
    "\n",
    "def main():\n",
    "    part = PART.upper()\n",
    "    root = os.path.abspath(\"dataset\")\n",
    "    gt_dir = os.path.join(root, f\"part_{part}\", \"test_data\", \"ground-truth\")\n",
    "    img_dir = os.path.join(root, f\"part_{part}\", \"test_data\", \"images\")\n",
    "\n",
    "    if not os.path.isdir(gt_dir):\n",
    "        raise FileNotFoundError(f\"Ground truth directory not found: {gt_dir}\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if MODEL:\n",
    "        model = load_model(MODEL, device)\n",
    "        evaluate(gt_dir, img_dir=img_dir, model=model, device=device)\n",
    "    elif PREDDIR:\n",
    "        pred_dir = os.path.abspath(PREDDIR)\n",
    "        evaluate(gt_dir, pred_dir=pred_dir)\n",
    "    else:\n",
    "        raise ValueError(\"You must provide either --model or --pred_dir\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
